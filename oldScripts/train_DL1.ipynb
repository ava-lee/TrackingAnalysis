{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b-tagging Machine Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training script for DL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from plottingFunctions import sigBkgEff\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense, Activation, Input, add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/eos/user/m/mguth/public/btagging-ml_tutorial_files\"\n",
    "trainfile_name = file_path+\"/MC16d_hybrid-training_sample-NN.h5\"\n",
    "h5f_train = h5py.File(trainfile_name, 'r')\n",
    "testfile_name = file_path+\"/MC16d_ttbar-test-validation_sample-NN.h5\"\n",
    "h5f_test = h5py.File(testfile_name, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = h5f_train['X_train'][:]\n",
    "Y_train = h5f_train['Y_train'][:]\n",
    "\n",
    "X_test = h5f_test['X_test'][:]\n",
    "Y_test = h5f_test['Y_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following the DL1 network is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 72)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 72)                288       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 57)                4161      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 57)                228       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                3480      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 48)                2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 36)                1764      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 18,120\n",
      "Trainable params: 17,490\n",
      "Non-trainable params: 630\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "# number of nodes in the different hidden layers\n",
    "l_units = [72, 57, 60, 48, 36, 24, 12, 6]\n",
    "x = inputs\n",
    "# loop to initialise the hidden layers\n",
    "for unit in l_units:\n",
    "    x = Dense(units=unit, activation=\"linear\", kernel_initializer='glorot_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "#     x = Dropout(0.1)\n",
    "# output layer, using softmax which will return a probability for each jet to be either light, c- or b-jet\n",
    "predictions = Dense(units=3, activation='softmax',\n",
    "                    kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "model_optimizer = Adam(lr=0.01)\n",
    "model.compile(  # loss='mse',\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=model_optimizer,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRejection(y_pred, y_true):\n",
    "    \"\"\"Calculates the c and light rejection for 77% WP and 0.018 c-fraction.\"\"\"\n",
    "    b_index, c_index, u_index = 2, 1, 0\n",
    "    cfrac = 0.018\n",
    "    target_beff = 0.77\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    b_jets = y_pred[y_true == b_index]\n",
    "    c_jets = y_pred[y_true == c_index]\n",
    "    u_jets = y_pred[y_true == u_index]\n",
    "    bscores = np.log(b_jets[:, b_index] / (cfrac * b_jets[:, c_index] +\n",
    "                                           (1 - cfrac) * b_jets[:, u_index]))\n",
    "    cutvalue = np.percentile(bscores, 100.0 * (1.0 - target_beff))\n",
    "\n",
    "    c_eff = len(c_jets[np.log(c_jets[:, b_index] / (cfrac * c_jets[:, c_index]\n",
    "                                                    + (1 - cfrac) *\n",
    "                                                    c_jets[:, u_index])) >\n",
    "                       cutvalue]) / float(len(c_jets))\n",
    "    u_eff = len(u_jets[np.log(u_jets[:, b_index] / (cfrac *\n",
    "                                                    u_jets[:, c_index] +\n",
    "                                                    (1 - cfrac) *\n",
    "                                                    u_jets[:, u_index])) >\n",
    "                       cutvalue]) / float(len(u_jets))\n",
    "\n",
    "    if c_eff == 0 or u_eff == 0:\n",
    "        return -1, -1\n",
    "    return 1. / c_eff, 1. / u_eff\n",
    "\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    \"\"\"Custom callback function calculating per epoch light and c-rejection and saves the model of each epoch.\"\"\"\n",
    "    def __init__(self, X_valid=0, Y_valid=0,\n",
    "                 model_name='test', store_all=False):\n",
    "        self.X_valid = X_valid\n",
    "        self.Y_valid = Y_valid\n",
    "        self.result = []\n",
    "        self.model_name = model_name\n",
    "        os.system(\"mkdir -p %s\" % self.model_name)\n",
    "        self.dict_list = []\n",
    "        self.store_all = store_all\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.store_all:\n",
    "            self.model.save('%s/model_epoch%i.h5' % (self.model_name, epoch))\n",
    "        y_pred = self.model.predict(self.X_valid, batch_size=5000)\n",
    "        c_rej, u_rej = GetRejection(y_pred, self.Y_valid)\n",
    "        dict_epoch = {\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": float(logs['loss']),\n",
    "            \"acc\": float(logs['accuracy']),\n",
    "            \"val_loss\": float(logs['val_loss']),\n",
    "            \"val_acc\": float(logs['val_accuracy']),\n",
    "            \"c_rej\": c_rej,\n",
    "            \"u_rej\": u_rej\n",
    "        }\n",
    "\n",
    "        self.dict_list.append(dict_epoch)\n",
    "        with open('%s/DictFile.json' % self.model_name, 'w') as outfile:\n",
    "            json.dump(self.dict_list, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2072727 samples, validate on 1928080 samples\n",
      "Epoch 1/10\n",
      "2072727/2072727 [==============================] - 23s 11us/step - loss: 0.7253 - accuracy: 0.6544 - val_loss: 0.6055 - val_accuracy: 0.7585\n",
      "Epoch 2/10\n",
      "2072727/2072727 [==============================] - 22s 11us/step - loss: 0.7227 - accuracy: 0.6556 - val_loss: 0.6174 - val_accuracy: 0.7599\n",
      "Epoch 3/10\n",
      "2072727/2072727 [==============================] - 22s 11us/step - loss: 0.7213 - accuracy: 0.6561 - val_loss: 0.5933 - val_accuracy: 0.7851\n",
      "Epoch 4/10\n",
      "2072727/2072727 [==============================] - 22s 11us/step - loss: 0.7203 - accuracy: 0.6565 - val_loss: 0.6173 - val_accuracy: 0.7632\n",
      "Epoch 5/10\n",
      "2070000/2072727 [============================>.] - ETA: 0s - loss: 0.7194 - accuracy: 0.6569"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001)\n",
    "my_callback = MyCallback(X_valid=X_test,\n",
    "                         Y_valid=Y_test,\n",
    "                         model_name=\"DL1_example\"\n",
    "#                         ,store_all=True #flag to store model of each epoch\n",
    "                        )\n",
    "\n",
    "callbacks = [reduce_lr, my_callback]\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          validation_data=[X_test[:], Y_test[:]],\n",
    "          epochs=10, # typically ~130 are necessary to converge\n",
    "          batch_size=3000,\n",
    "          callbacks=callbacks,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_json(\"DL1_example/DictFile.json\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_results['epoch'],df_results['loss'], label='training loss - hybrid sample')\n",
    "plt.plot(df_results['epoch'],df_results['val_loss'], label='validation loss - ttbar sample')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('light flavour jet rejection', color=color)\n",
    "ax1.plot(df_results[\"epoch\"],df_results['u_rej'], '--', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel(r'$c$-jet rejection', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(df_results[\"epoch\"], df_results['c_rej'], ':', color=color, label='std = 0.12')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter optimisation\n",
    "You can play with different hyper parameters and see their impact.\n",
    "The largest impact has the NN-structure itself, you can try changing the number of hidden layers and their number of nodes\n",
    "Other hyper parameters are the learning rate, activation function, batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_effs = np.linspace(0.39, 1, 150)\n",
    "l_rej = 1./np.load(\"DL1r-extbeff-22M.npy\", allow_pickle=True).item().get('urej')\n",
    "c_rej = 1./np.load(\"DL1r-extbeff-22M.npy\", allow_pickle=True).item().get('crej')\n",
    "\n",
    "l_rej_Z = 1./np.load(\"DL1r-extbeff-22M-ext-Zprime.npy\", allow_pickle=True).item().get('urej')\n",
    "c_rej_Z = 1./np.load(\"DL1r-extbeff-22M-ext-Zprime.npy\", allow_pickle=True).item().get('crej')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw the roc curves faster, look at a subset of the test dataset. \n",
    "nTest = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl1_leffs, dl1_ceffs, dl1_beffs, dl1_discs = [], [], [], []\n",
    "\n",
    "for testfile_name in [file_path+\"/MC16d_ttbar-test-validation_sample-NN.h5\",\n",
    "                      file_path+\"/MC16d_Zprime-test-validation_sample-NN.h5\"]:\n",
    "    \n",
    "    print(testfile_name)\n",
    "    h5f_test = h5py.File(testfile_name, 'r')\n",
    "\n",
    "    X_test = h5f_test['X_test'][500000:]\n",
    "    y_test = h5f_test['Y_test'][500000:]\n",
    "    \n",
    "    h5f_test.close()\n",
    "\n",
    "    (leff, ceff, beff), d = sigBkgEff(model, X_test[:nTest], y_test[:nTest], returnDisc=True, fc=0.018)\n",
    "     \n",
    "    dl1_leffs.append(leff)\n",
    "    dl1_ceffs.append(ceff)\n",
    "    dl1_beffs.append(beff)\n",
    "    dl1_discs.append(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttbar\n",
    "plt.figure()\n",
    "plt.plot(dl1_beffs[0], 1 / dl1_leffs[0], color='C4', label='l-rej')\n",
    "plt.plot(b_effs, 1./l_rej, color='C2', label='l-rej - new recommendations')\n",
    "\n",
    "# plt.figure()\n",
    "plt.plot(dl1_beffs[0], 1 / dl1_ceffs[0],\"--\", color='C4', label='c-rej')\n",
    "plt.plot(b_effs, 1./c_rej, \"--\", color='C2', label='c-rej - new recommendations')\n",
    "\n",
    "plt.ylabel('background-rej')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r'$t\\bar{t}$- PFlow - DL1r')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(0.6,1)\n",
    "plt.ylim(0,3000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z'\n",
    "plt.figure()\n",
    "plt.plot(dl1_beffs[1], 1 / dl1_leffs[1], color='C4', label='l-rej')\n",
    "plt.plot(b_effs, 1./l_rej_Z, color='C2', label='l-rej - new recommendations')\n",
    "\n",
    "# plt.figure()\n",
    "plt.plot(dl1_beffs[1], 1 / dl1_ceffs[1],\"--\", color='C4', label='c-rej')\n",
    "plt.plot(b_effs, 1./c_rej_Z, \"--\", color='C2', label='c-rej - new recommendations')\n",
    "\n",
    "plt.ylabel('background-rej')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Extended Z'- PFlow - DL1r\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(0.6,1)\n",
    "plt.ylim(0,3000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
